{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T10:25:32.850266Z",
     "start_time": "2025-11-03T10:25:32.481838Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DataSet",
   "id": "7397503d97a20626"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:26:00.204063Z",
     "start_time": "2025-11-03T10:25:59.886735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = make_multilabel_classification(n_samples=2000, n_classes=5, n_features=20, n_labels=2, random_state=42)\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(data[0])\n",
    "\n",
    "data_df"
   ],
   "id": "6f5343be7e6e7ffe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0     3.0  0.0  2.0  2.0  2.0  8.0  3.0  2.0  5.0  2.0  0.0  1.0  0.0  1.0   \n",
       "1     3.0  5.0  2.0  3.0  3.0  3.0  1.0  1.0  4.0  1.0  1.0  4.0  2.0  8.0   \n",
       "2     3.0  2.0  3.0  1.0  0.0  5.0  3.0  2.0  2.0  7.0  2.0  2.0  2.0  4.0   \n",
       "3     1.0  0.0  1.0  6.0  6.0  1.0  4.0  1.0  2.0  7.0  8.0  2.0  5.0  5.0   \n",
       "4     3.0  6.0  2.0  1.0  1.0  2.0  5.0  1.0  4.0  5.0  2.0  1.0  5.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1995  4.0  0.0  1.0  4.0  0.0  4.0  2.0  2.0  3.0  4.0  1.0  1.0  4.0  1.0   \n",
       "1996  0.0  5.0  2.0  1.0  1.0  3.0  2.0  2.0  1.0  4.0  0.0  1.0  1.0  0.0   \n",
       "1997  1.0  0.0  3.0  4.0  6.0  4.0  3.0  0.0  2.0  5.0  5.0  0.0  3.0  2.0   \n",
       "1998  1.0  1.0  1.0  2.0  2.0  5.0  1.0  5.0  0.0  7.0  1.0  5.0  0.0  2.0   \n",
       "1999  0.0  3.0  2.0  0.0  8.0  4.0  3.0  3.0  4.0  4.0  2.0  0.0  1.0  4.0   \n",
       "\n",
       "       14   15   16   17   18   19  \n",
       "0     0.0  0.0  6.0  5.0  0.0  2.0  \n",
       "1     4.0  3.0  2.0  6.0  2.0  0.0  \n",
       "2     1.0  0.0  6.0  6.0  3.0  3.0  \n",
       "3     3.0  2.0  0.0  0.0  3.0  0.0  \n",
       "4     5.0  7.0  3.0  5.0  4.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  \n",
       "1995  1.0  3.0  3.0  5.0  0.0  7.0  \n",
       "1996  8.0  6.0  7.0  4.0  1.0  2.0  \n",
       "1997  4.0  3.0  1.0  1.0  2.0  0.0  \n",
       "1998  4.0  0.0  4.0  2.0  4.0  4.0  \n",
       "1999  4.0  2.0  6.0  0.0  5.0  2.0  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Data Correlation",
   "id": "e3a9a08dc9000bac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:29:42.318804Z",
     "start_time": "2025-11-03T10:29:41.905687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = data_df.columns[:20]\n",
    "corr_mtx = (data_df[names]).corr(method='pearson')\n",
    "plt.matshow(corr_mtx, cmap=\"grey\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks(range(len(names)), names, rotation=90)\n",
    "plt.yticks(range(len(names)), names)\n",
    "plt.show()\n",
    "\n",
    "corr_mtx"
   ],
   "id": "772fc1210dc861b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000 -0.086534  0.096326  0.003211  0.073208  0.042363 -0.097406   \n",
       "1  -0.086534  1.000000  0.064790 -0.228097 -0.157790 -0.350280 -0.225607   \n",
       "2   0.096326  0.064790  1.000000 -0.045731  0.023860 -0.050681 -0.122408   \n",
       "3   0.003211 -0.228097 -0.045731  1.000000  0.061768  0.116322  0.091986   \n",
       "4   0.073208 -0.157790  0.023860  0.061768  1.000000  0.022773  0.051948   \n",
       "5   0.042363 -0.350280 -0.050681  0.116322  0.022773  1.000000  0.230318   \n",
       "6  -0.097406 -0.225607 -0.122408  0.091986  0.051948  0.230318  1.000000   \n",
       "7  -0.074994 -0.037026 -0.011885 -0.066284 -0.042929  0.207961  0.142533   \n",
       "8   0.039464 -0.044538 -0.019062  0.000845  0.144489  0.015438  0.007080   \n",
       "9   0.020703  0.057443 -0.009165 -0.085146  0.030747 -0.075841 -0.044297   \n",
       "10 -0.050460 -0.230962 -0.082936  0.156692  0.129286  0.058862  0.121756   \n",
       "11  0.195415  0.058072  0.101075 -0.038326  0.031615 -0.118137 -0.102433   \n",
       "12  0.258501 -0.032330  0.078989  0.091689  0.007206 -0.105371 -0.135858   \n",
       "13 -0.046485 -0.341130 -0.081273  0.154193  0.074538  0.324525  0.238965   \n",
       "14 -0.336665  0.127271 -0.115780 -0.031506 -0.064917 -0.098683  0.080862   \n",
       "15 -0.218460  0.118413 -0.076425 -0.008971 -0.028807 -0.157430  0.016217   \n",
       "16 -0.033266  0.095120  0.031613 -0.099452 -0.013019  0.004939 -0.060310   \n",
       "17  0.044423  0.219150  0.035556 -0.096897 -0.170197 -0.108941 -0.158005   \n",
       "18 -0.155753  0.193464 -0.009010 -0.039654 -0.067214 -0.223719 -0.090791   \n",
       "19 -0.040195  0.086438 -0.033134 -0.075726 -0.177357  0.042116 -0.008397   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0  -0.074994  0.039464  0.020703 -0.050460  0.195415  0.258501 -0.046485   \n",
       "1  -0.037026 -0.044538  0.057443 -0.230962  0.058072 -0.032330 -0.341130   \n",
       "2  -0.011885 -0.019062 -0.009165 -0.082936  0.101075  0.078989 -0.081273   \n",
       "3  -0.066284  0.000845 -0.085146  0.156692 -0.038326  0.091689  0.154193   \n",
       "4  -0.042929  0.144489  0.030747  0.129286  0.031615  0.007206  0.074538   \n",
       "5   0.207961  0.015438 -0.075841  0.058862 -0.118137 -0.105371  0.324525   \n",
       "6   0.142533  0.007080 -0.044297  0.121756 -0.102433 -0.135858  0.238965   \n",
       "7   1.000000 -0.038428 -0.033128 -0.189151 -0.133456 -0.312520  0.175325   \n",
       "8  -0.038428  1.000000  0.005527  0.072945  0.025678  0.018521 -0.022162   \n",
       "9  -0.033128  0.005527  1.000000 -0.100339  0.075849  0.011462 -0.088330   \n",
       "10 -0.189151  0.072945 -0.100339  1.000000 -0.013238  0.144035  0.093711   \n",
       "11 -0.133456  0.025678  0.075849 -0.013238  1.000000  0.138834 -0.166294   \n",
       "12 -0.312520  0.018521  0.011462  0.144035  0.138834  1.000000 -0.154970   \n",
       "13  0.175325 -0.022162 -0.088330  0.093711 -0.166294 -0.154970  1.000000   \n",
       "14  0.109989 -0.053774 -0.008336  0.040893 -0.172371 -0.261894  0.016268   \n",
       "15 -0.146426 -0.009596 -0.017189  0.166493 -0.043534 -0.019775 -0.064545   \n",
       "16  0.081250  0.006847  0.059827 -0.218307 -0.050901 -0.132572 -0.026277   \n",
       "17 -0.026589 -0.063334  0.029617 -0.196815  0.063725  0.065291 -0.132909   \n",
       "18 -0.104916 -0.032923 -0.013704  0.109800  0.011365  0.026085 -0.194575   \n",
       "19  0.114267 -0.115956 -0.039086 -0.205940 -0.076966 -0.072761 -0.008360   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "0  -0.336665 -0.218460 -0.033266  0.044423 -0.155753 -0.040195  \n",
       "1   0.127271  0.118413  0.095120  0.219150  0.193464  0.086438  \n",
       "2  -0.115780 -0.076425  0.031613  0.035556 -0.009010 -0.033134  \n",
       "3  -0.031506 -0.008971 -0.099452 -0.096897 -0.039654 -0.075726  \n",
       "4  -0.064917 -0.028807 -0.013019 -0.170197 -0.067214 -0.177357  \n",
       "5  -0.098683 -0.157430  0.004939 -0.108941 -0.223719  0.042116  \n",
       "6   0.080862  0.016217 -0.060310 -0.158005 -0.090791 -0.008397  \n",
       "7   0.109989 -0.146426  0.081250 -0.026589 -0.104916  0.114267  \n",
       "8  -0.053774 -0.009596  0.006847 -0.063334 -0.032923 -0.115956  \n",
       "9  -0.008336 -0.017189  0.059827  0.029617 -0.013704 -0.039086  \n",
       "10  0.040893  0.166493 -0.218307 -0.196815  0.109800 -0.205940  \n",
       "11 -0.172371 -0.043534 -0.050901  0.063725  0.011365 -0.076966  \n",
       "12 -0.261894 -0.019775 -0.132572  0.065291  0.026085 -0.072761  \n",
       "13  0.016268 -0.064545 -0.026277 -0.132909 -0.194575 -0.008360  \n",
       "14  1.000000  0.206069  0.036039 -0.067191  0.155818  0.025847  \n",
       "15  0.206069  1.000000 -0.113517 -0.025580  0.210710 -0.031663  \n",
       "16  0.036039 -0.113517  1.000000  0.094195 -0.048996  0.054992  \n",
       "17 -0.067191 -0.025580  0.094195  1.000000  0.032577  0.140690  \n",
       "18  0.155818  0.210710 -0.048996  0.032577  1.000000 -0.016621  \n",
       "19  0.025847 -0.031663  0.054992  0.140690 -0.016621  1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.086534</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.073208</td>\n",
       "      <td>0.042363</td>\n",
       "      <td>-0.097406</td>\n",
       "      <td>-0.074994</td>\n",
       "      <td>0.039464</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>-0.050460</td>\n",
       "      <td>0.195415</td>\n",
       "      <td>0.258501</td>\n",
       "      <td>-0.046485</td>\n",
       "      <td>-0.336665</td>\n",
       "      <td>-0.218460</td>\n",
       "      <td>-0.033266</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>-0.155753</td>\n",
       "      <td>-0.040195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.086534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064790</td>\n",
       "      <td>-0.228097</td>\n",
       "      <td>-0.157790</td>\n",
       "      <td>-0.350280</td>\n",
       "      <td>-0.225607</td>\n",
       "      <td>-0.037026</td>\n",
       "      <td>-0.044538</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>-0.230962</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>-0.032330</td>\n",
       "      <td>-0.341130</td>\n",
       "      <td>0.127271</td>\n",
       "      <td>0.118413</td>\n",
       "      <td>0.095120</td>\n",
       "      <td>0.219150</td>\n",
       "      <td>0.193464</td>\n",
       "      <td>0.086438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.064790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>0.023860</td>\n",
       "      <td>-0.050681</td>\n",
       "      <td>-0.122408</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>-0.019062</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.082936</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.078989</td>\n",
       "      <td>-0.081273</td>\n",
       "      <td>-0.115780</td>\n",
       "      <td>-0.076425</td>\n",
       "      <td>0.031613</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.033134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003211</td>\n",
       "      <td>-0.228097</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>-0.066284</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>-0.085146</td>\n",
       "      <td>0.156692</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>0.091689</td>\n",
       "      <td>0.154193</td>\n",
       "      <td>-0.031506</td>\n",
       "      <td>-0.008971</td>\n",
       "      <td>-0.099452</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>-0.039654</td>\n",
       "      <td>-0.075726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073208</td>\n",
       "      <td>-0.157790</td>\n",
       "      <td>0.023860</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>-0.042929</td>\n",
       "      <td>0.144489</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.129286</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>-0.028807</td>\n",
       "      <td>-0.013019</td>\n",
       "      <td>-0.170197</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>-0.177357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042363</td>\n",
       "      <td>-0.350280</td>\n",
       "      <td>-0.050681</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>0.207961</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>-0.075841</td>\n",
       "      <td>0.058862</td>\n",
       "      <td>-0.118137</td>\n",
       "      <td>-0.105371</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>-0.098683</td>\n",
       "      <td>-0.157430</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>-0.108941</td>\n",
       "      <td>-0.223719</td>\n",
       "      <td>0.042116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.097406</td>\n",
       "      <td>-0.225607</td>\n",
       "      <td>-0.122408</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.230318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142533</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>-0.044297</td>\n",
       "      <td>0.121756</td>\n",
       "      <td>-0.102433</td>\n",
       "      <td>-0.135858</td>\n",
       "      <td>0.238965</td>\n",
       "      <td>0.080862</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>-0.158005</td>\n",
       "      <td>-0.090791</td>\n",
       "      <td>-0.008397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.074994</td>\n",
       "      <td>-0.037026</td>\n",
       "      <td>-0.011885</td>\n",
       "      <td>-0.066284</td>\n",
       "      <td>-0.042929</td>\n",
       "      <td>0.207961</td>\n",
       "      <td>0.142533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038428</td>\n",
       "      <td>-0.033128</td>\n",
       "      <td>-0.189151</td>\n",
       "      <td>-0.133456</td>\n",
       "      <td>-0.312520</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.109989</td>\n",
       "      <td>-0.146426</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>-0.026589</td>\n",
       "      <td>-0.104916</td>\n",
       "      <td>0.114267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039464</td>\n",
       "      <td>-0.044538</td>\n",
       "      <td>-0.019062</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.144489</td>\n",
       "      <td>0.015438</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>-0.038428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.072945</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.018521</td>\n",
       "      <td>-0.022162</td>\n",
       "      <td>-0.053774</td>\n",
       "      <td>-0.009596</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.063334</td>\n",
       "      <td>-0.032923</td>\n",
       "      <td>-0.115956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.085146</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>-0.075841</td>\n",
       "      <td>-0.044297</td>\n",
       "      <td>-0.033128</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100339</td>\n",
       "      <td>0.075849</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>-0.088330</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.029617</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.039086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.050460</td>\n",
       "      <td>-0.230962</td>\n",
       "      <td>-0.082936</td>\n",
       "      <td>0.156692</td>\n",
       "      <td>0.129286</td>\n",
       "      <td>0.058862</td>\n",
       "      <td>0.121756</td>\n",
       "      <td>-0.189151</td>\n",
       "      <td>0.072945</td>\n",
       "      <td>-0.100339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013238</td>\n",
       "      <td>0.144035</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>0.040893</td>\n",
       "      <td>0.166493</td>\n",
       "      <td>-0.218307</td>\n",
       "      <td>-0.196815</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>-0.205940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.195415</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>-0.038326</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>-0.118137</td>\n",
       "      <td>-0.102433</td>\n",
       "      <td>-0.133456</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.075849</td>\n",
       "      <td>-0.013238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138834</td>\n",
       "      <td>-0.166294</td>\n",
       "      <td>-0.172371</td>\n",
       "      <td>-0.043534</td>\n",
       "      <td>-0.050901</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>-0.076966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.258501</td>\n",
       "      <td>-0.032330</td>\n",
       "      <td>0.078989</td>\n",
       "      <td>0.091689</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>-0.105371</td>\n",
       "      <td>-0.135858</td>\n",
       "      <td>-0.312520</td>\n",
       "      <td>0.018521</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>0.144035</td>\n",
       "      <td>0.138834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154970</td>\n",
       "      <td>-0.261894</td>\n",
       "      <td>-0.019775</td>\n",
       "      <td>-0.132572</td>\n",
       "      <td>0.065291</td>\n",
       "      <td>0.026085</td>\n",
       "      <td>-0.072761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.046485</td>\n",
       "      <td>-0.341130</td>\n",
       "      <td>-0.081273</td>\n",
       "      <td>0.154193</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>0.238965</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>-0.022162</td>\n",
       "      <td>-0.088330</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>-0.166294</td>\n",
       "      <td>-0.154970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.026277</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>-0.194575</td>\n",
       "      <td>-0.008360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.336665</td>\n",
       "      <td>0.127271</td>\n",
       "      <td>-0.115780</td>\n",
       "      <td>-0.031506</td>\n",
       "      <td>-0.064917</td>\n",
       "      <td>-0.098683</td>\n",
       "      <td>0.080862</td>\n",
       "      <td>0.109989</td>\n",
       "      <td>-0.053774</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>0.040893</td>\n",
       "      <td>-0.172371</td>\n",
       "      <td>-0.261894</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206069</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.155818</td>\n",
       "      <td>0.025847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.218460</td>\n",
       "      <td>0.118413</td>\n",
       "      <td>-0.076425</td>\n",
       "      <td>-0.008971</td>\n",
       "      <td>-0.028807</td>\n",
       "      <td>-0.157430</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>-0.146426</td>\n",
       "      <td>-0.009596</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>0.166493</td>\n",
       "      <td>-0.043534</td>\n",
       "      <td>-0.019775</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>0.206069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.113517</td>\n",
       "      <td>-0.025580</td>\n",
       "      <td>0.210710</td>\n",
       "      <td>-0.031663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.033266</td>\n",
       "      <td>0.095120</td>\n",
       "      <td>0.031613</td>\n",
       "      <td>-0.099452</td>\n",
       "      <td>-0.013019</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>-0.218307</td>\n",
       "      <td>-0.050901</td>\n",
       "      <td>-0.132572</td>\n",
       "      <td>-0.026277</td>\n",
       "      <td>0.036039</td>\n",
       "      <td>-0.113517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094195</td>\n",
       "      <td>-0.048996</td>\n",
       "      <td>0.054992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.219150</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>-0.170197</td>\n",
       "      <td>-0.108941</td>\n",
       "      <td>-0.158005</td>\n",
       "      <td>-0.026589</td>\n",
       "      <td>-0.063334</td>\n",
       "      <td>0.029617</td>\n",
       "      <td>-0.196815</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.065291</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>-0.025580</td>\n",
       "      <td>0.094195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032577</td>\n",
       "      <td>0.140690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.155753</td>\n",
       "      <td>0.193464</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.039654</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>-0.223719</td>\n",
       "      <td>-0.090791</td>\n",
       "      <td>-0.104916</td>\n",
       "      <td>-0.032923</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.026085</td>\n",
       "      <td>-0.194575</td>\n",
       "      <td>0.155818</td>\n",
       "      <td>0.210710</td>\n",
       "      <td>-0.048996</td>\n",
       "      <td>0.032577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.040195</td>\n",
       "      <td>0.086438</td>\n",
       "      <td>-0.033134</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>-0.177357</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>-0.008397</td>\n",
       "      <td>0.114267</td>\n",
       "      <td>-0.115956</td>\n",
       "      <td>-0.039086</td>\n",
       "      <td>-0.205940</td>\n",
       "      <td>-0.076966</td>\n",
       "      <td>-0.072761</td>\n",
       "      <td>-0.008360</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>0.054992</td>\n",
       "      <td>0.140690</td>\n",
       "      <td>-0.016621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Split",
   "id": "6a68affb9cebfaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:32:57.764385Z",
     "start_time": "2025-11-03T10:32:57.706514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3)"
   ],
   "id": "32c625c2fc4490f5",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MultiLabels Model (Wrappers)",
   "id": "bf72dce8a56dfca2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:39:05.853009Z",
     "start_time": "2025-11-03T10:39:05.845951Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.multioutput import MultiOutputClassifier",
   "id": "a2105994029e9423",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metric Function",
   "id": "f2bd2aa38685d61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:39:04.144701Z",
     "start_time": "2025-11-03T10:39:04.097820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,  # Dodano Precision\n",
    "    recall_score      # Dodano Recall dla uÅ‚atwienia\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "def metrics_multiclass(y_true: np.ndarray, y_pred_classes: np.ndarray, y_pred_scores: np.ndarray, method: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates and plots classification metrics (Accuracy, Precision, Recall, Specificity, AUC)\n",
    "    for multiclass classification, displaying results in a Pandas DataFrame table.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels (ground truth).\n",
    "        y_pred_classes (np.ndarray): Predicted class labels.\n",
    "        y_pred_scores (np.ndarray): Predicted probabilities (or decision scores) for each class.\n",
    "                                     Shape should be (n_samples, n_classes).\n",
    "        method (str): Name of the classification method (for plot title).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the combined per-class and macro-averaged metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1. Obliczenia\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    cf_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # Scikit-learn calculation (easier and more robust)\n",
    "    recall_per_class = recall_score(y_true, y_pred_classes, average=None, zero_division=0)\n",
    "    precision_per_class = precision_score(y_true, y_pred_classes, average=None, zero_division=0)\n",
    "\n",
    "    # RÄ™czne obliczenie SpecyficznoÅ›ci (One-vs-Rest)\n",
    "    specificity_per_class = []\n",
    "    for i in range(n_classes):\n",
    "        TP = cf_mtx[i, i]\n",
    "        FN = np.sum(cf_mtx[i, :]) - TP\n",
    "        FP = np.sum(cf_mtx[:, i]) - TP\n",
    "        TN = np.sum(cf_mtx) - (TP + FN + FP)\n",
    "\n",
    "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        specificity_per_class.append(specificity)\n",
    "\n",
    "    # Obliczenie AUC (One-vs-Rest)\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    roc_auc_per_class = []\n",
    "\n",
    "    # Collect AUC for plotting and report\n",
    "    for i in range(n_classes):\n",
    "        roc_auc_class = roc_auc_score(y_true_bin[:, i], y_pred_scores[:, i])\n",
    "        roc_auc_per_class.append(roc_auc_class)\n",
    "\n",
    "    roc_area_macro = roc_auc_score(y_true_bin, y_pred_scores, multi_class='ovr', average='macro')\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. Tworzenie DataFrame z Metrykami\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Metryki dla kaÅ¼dej klasy\n",
    "    df_per_class = pd.DataFrame({\n",
    "        'Klasa': classes,\n",
    "        'CzuÅ‚oÅ›Ä‡ (Recall)': recall_per_class,\n",
    "        'Precyzja (Precision)': precision_per_class,\n",
    "        'SpecyficznoÅ›Ä‡': specificity_per_class,\n",
    "        'AUC (OvR)': roc_auc_per_class\n",
    "    })\n",
    "\n",
    "    # Metryki UÅ›rednione\n",
    "    macro_row = pd.DataFrame({\n",
    "        'Klasa': ['Macro-Avg', 'Accuracy (overall)'],\n",
    "        'CzuÅ‚oÅ›Ä‡ (Recall)': [np.mean(recall_per_class), np.nan],\n",
    "        'Precyzja (Precision)': [np.mean(precision_per_class), np.nan],\n",
    "        'SpecyficznoÅ›Ä‡': [np.mean(specificity_per_class), np.nan],\n",
    "        'AUC (OvR)': [roc_area_macro, np.nan]\n",
    "    })\n",
    "\n",
    "    # Metryka OgÃ³lna (Accuracy)\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'Klasa': ['Accuracy (overall)'],\n",
    "        'CzuÅ‚oÅ›Ä‡ (Recall)': [np.nan],\n",
    "        'Precyzja (Precision)': [np.nan],\n",
    "        'SpecyficznoÅ›Ä‡': [np.nan],\n",
    "        'AUC (OvR)': [np.nan]\n",
    "    })\n",
    "\n",
    "    # ÅÄ…czenie i dodanie Accuracy w osobnym wierszu\n",
    "    df_metrics = pd.concat([df_per_class, macro_row]).reset_index(drop=True)\n",
    "    df_metrics.loc[df_metrics['Klasa'] == 'Accuracy (overall)', 'CzuÅ‚oÅ›Ä‡ (Recall)'] = accuracy # UÅ¼ywamy dowolnej komÃ³rki 'Overall' do wstawienia Accuracy\n",
    "    df_metrics.loc[df_metrics['Klasa'] == 'Accuracy (overall)', 'Precyzja (Precision)'] = accuracy\n",
    "    df_metrics.loc[df_metrics['Klasa'] == 'Accuracy (overall)', 'SpecyficznoÅ›Ä‡'] = accuracy\n",
    "    df_metrics.loc[df_metrics['Klasa'] == 'Accuracy (overall)', 'AUC (OvR)'] = accuracy\n",
    "    df_metrics.rename(columns={'CzuÅ‚oÅ›Ä‡ (Recall)': 'Recall',\n",
    "                               'Precyzja (Precision)': 'Precision',\n",
    "                               'SpecyficznoÅ›Ä‡': 'Specifity',\n",
    "                               'AUC (OvR)': 'AUC_score'}, inplace=True)\n",
    "\n",
    "    # WyrÃ³Å¼nienie wierszy\n",
    "    # Wyczyszczenie NaN\n",
    "    df_metrics = df_metrics.fillna('')\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3. Plotting\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # UÅ¼ywamy wiÄ™kszego figsize\n",
    "    fig, ( ax_matrix, ax_roc) = plt.subplots(1, 2, figsize=(22, 6))\n",
    "\n",
    "    # 1. Confusion Matrix Display\n",
    "    cf_mtx_disp = ConfusionMatrixDisplay(confusion_matrix=cf_mtx, display_labels=classes)\n",
    "    cf_mtx_disp.plot(ax=ax_matrix, cmap='grey', values_format='d')\n",
    "    ax_matrix.set_title(\"Macierz PomyÅ‚ek\", fontsize=14)\n",
    "\n",
    "    # 3. ROC Curve Display (Plotting OvR for each class)\n",
    "    ax_roc.set_title(f'Krzywe ROC (One-vs-Rest)\\nMacro AUC: {roc_area_macro:.4f}', fontsize=14)\n",
    "    ax_roc.plot([0, 1], [0, 1], 'k--', label='Losowy (AUC = 0.5)', alpha=0.6) # Diagonal line\n",
    "\n",
    "    # Calculate and plot ROC for each class\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple', 'orange']) # DodaÅ‚em wiÄ™cej kolorÃ³w na wszelki wypadek\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_scores[:, i])\n",
    "\n",
    "        ax_roc.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            linewidth=2,\n",
    "            label=f'Klasa {classes[i]} (AUC: {roc_auc_per_class[i]:.2f})',\n",
    "            color=color,\n",
    "            alpha=0.7\n",
    "        )\n",
    "\n",
    "    ax_roc.set_xlabel('Odsetek FaÅ‚szywie Pozytywnych (FPR)')\n",
    "    ax_roc.set_ylabel('CzuÅ‚oÅ›Ä‡ (TPR)')\n",
    "    ax_roc.legend(loc=\"lower right\", fontsize=9)\n",
    "    ax_roc.grid(linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ZwrÃ³cenie skonsolidowanego DataFrame\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "\n",
    "model_performence = {}"
   ],
   "id": "55484d93956f13e3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic Regression",
   "id": "972e811fc21977f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T10:50:51.020916Z",
     "start_time": "2025-11-03T10:50:18.192979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def objective_lr(trial):\n",
    "    C = trial.suggest_float('C', 1e-3, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 200)\n",
    "\n",
    "    clf = MultiOutputClassifier(LogisticRegression(C=C, solver=solver, max_iter=max_iter, random_state=42))\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_lr, n_trials=100)\n",
    "\n",
    "study.best_params"
   ],
   "id": "647696954001547e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-03 11:50:18,205] A new study created in memory with name: no-name-43b145e7-984b-42da-9aef-8626c83805ed\n",
      "[I 2025-11-03 11:50:18,509] Trial 0 finished with value: 0.4135714285714286 and parameters: {'C': 2.0347997655205496, 'solver': 'liblinear', 'max_iter': 154}. Best is trial 0 with value: 0.4135714285714286.\n",
      "[I 2025-11-03 11:50:18,598] Trial 1 finished with value: 0.4142857142857143 and parameters: {'C': 2.2092358787606163, 'solver': 'liblinear', 'max_iter': 138}. Best is trial 0 with value: 0.4135714285714286.\n",
      "[I 2025-11-03 11:50:18,690] Trial 2 finished with value: 0.4142857142857143 and parameters: {'C': 3.3912939885002067, 'solver': 'liblinear', 'max_iter': 141}. Best is trial 0 with value: 0.4135714285714286.\n",
      "[I 2025-11-03 11:50:18,935] Trial 3 finished with value: 0.41571428571428576 and parameters: {'C': 0.0030613574299337637, 'solver': 'lbfgs', 'max_iter': 118}. Best is trial 0 with value: 0.4135714285714286.\n",
      "[I 2025-11-03 11:50:19,337] Trial 4 finished with value: 0.4135714285714286 and parameters: {'C': 72.25096078646503, 'solver': 'lbfgs', 'max_iter': 145}. Best is trial 0 with value: 0.4135714285714286.\n",
      "[I 2025-11-03 11:50:19,468] Trial 5 finished with value: 0.4128571428571429 and parameters: {'C': 0.7084767440799181, 'solver': 'liblinear', 'max_iter': 168}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:20,504] Trial 6 finished with value: 0.4178571428571428 and parameters: {'C': 0.014298286793473123, 'solver': 'saga', 'max_iter': 183}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:21,591] Trial 7 finished with value: 0.42000000000000004 and parameters: {'C': 0.019040305186708656, 'solver': 'saga', 'max_iter': 197}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:22,541] Trial 8 finished with value: 0.41714285714285715 and parameters: {'C': 0.004823797794894179, 'solver': 'saga', 'max_iter': 181}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:23,498] Trial 9 finished with value: 0.4185714285714286 and parameters: {'C': 0.011961862849405315, 'solver': 'saga', 'max_iter': 164}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:23,576] Trial 10 finished with value: 0.41785714285714287 and parameters: {'C': 0.14336373747529915, 'solver': 'liblinear', 'max_iter': 105}. Best is trial 5 with value: 0.4128571428571429.\n",
      "[I 2025-11-03 11:50:23,661] Trial 11 finished with value: 0.4121428571428572 and parameters: {'C': 1.0522860253737012, 'solver': 'liblinear', 'max_iter': 161}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:23,739] Trial 12 finished with value: 0.41500000000000004 and parameters: {'C': 0.24695917952895646, 'solver': 'liblinear', 'max_iter': 165}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:23,824] Trial 13 finished with value: 0.4135714285714286 and parameters: {'C': 20.05599152613748, 'solver': 'liblinear', 'max_iter': 175}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:23,900] Trial 14 finished with value: 0.41714285714285715 and parameters: {'C': 0.09284448677863341, 'solver': 'liblinear', 'max_iter': 125}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:23,982] Trial 15 finished with value: 0.4142857142857143 and parameters: {'C': 0.8373677537524391, 'solver': 'liblinear', 'max_iter': 199}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,257] Trial 16 finished with value: 0.4135714285714286 and parameters: {'C': 11.712096781669295, 'solver': 'lbfgs', 'max_iter': 161}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,390] Trial 17 finished with value: 0.4135714285714286 and parameters: {'C': 0.49887872729045524, 'solver': 'liblinear', 'max_iter': 175}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,465] Trial 18 finished with value: 0.41785714285714287 and parameters: {'C': 0.06725309971149537, 'solver': 'liblinear', 'max_iter': 154}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,711] Trial 19 finished with value: 0.4135714285714286 and parameters: {'C': 7.956192555387255, 'solver': 'lbfgs', 'max_iter': 131}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,851] Trial 20 finished with value: 0.4128571428571429 and parameters: {'C': 1.242789871246168, 'solver': 'liblinear', 'max_iter': 190}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:24,934] Trial 21 finished with value: 0.4128571428571429 and parameters: {'C': 1.250732829373719, 'solver': 'liblinear', 'max_iter': 188}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,009] Trial 22 finished with value: 0.4135714285714286 and parameters: {'C': 0.4252739850619158, 'solver': 'liblinear', 'max_iter': 170}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,096] Trial 23 finished with value: 0.4142857142857143 and parameters: {'C': 5.097702457009468, 'solver': 'liblinear', 'max_iter': 191}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,185] Trial 24 finished with value: 0.4135714285714286 and parameters: {'C': 38.47750037102231, 'solver': 'liblinear', 'max_iter': 159}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,263] Trial 25 finished with value: 0.4192857142857143 and parameters: {'C': 0.04285144646228049, 'solver': 'liblinear', 'max_iter': 173}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,344] Trial 26 finished with value: 0.4142857142857143 and parameters: {'C': 0.8022536724697106, 'solver': 'liblinear', 'max_iter': 149}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,422] Trial 27 finished with value: 0.4185714285714286 and parameters: {'C': 0.18778277794509116, 'solver': 'liblinear', 'max_iter': 183}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:25,694] Trial 28 finished with value: 0.4135714285714286 and parameters: {'C': 1.2291848033751136, 'solver': 'lbfgs', 'max_iter': 166}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:26,667] Trial 29 finished with value: 0.4121428571428572 and parameters: {'C': 4.422077863178266, 'solver': 'saga', 'max_iter': 154}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:27,580] Trial 30 finished with value: 0.4121428571428572 and parameters: {'C': 3.362665275735168, 'solver': 'saga', 'max_iter': 153}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:28,501] Trial 31 finished with value: 0.4121428571428572 and parameters: {'C': 2.546786680731187, 'solver': 'saga', 'max_iter': 155}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:29,407] Trial 32 finished with value: 0.4121428571428572 and parameters: {'C': 2.4923065594651885, 'solver': 'saga', 'max_iter': 154}. Best is trial 11 with value: 0.4121428571428572.\n",
      "[I 2025-11-03 11:50:30,243] Trial 33 finished with value: 0.4114285714285715 and parameters: {'C': 4.576630619082105, 'solver': 'saga', 'max_iter': 138}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:31,060] Trial 34 finished with value: 0.4121428571428572 and parameters: {'C': 16.546502973601843, 'solver': 'saga', 'max_iter': 135}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:31,917] Trial 35 finished with value: 0.4121428571428572 and parameters: {'C': 5.031054597063726, 'solver': 'saga', 'max_iter': 135}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:32,795] Trial 36 finished with value: 0.4128571428571429 and parameters: {'C': 33.171039928152894, 'solver': 'saga', 'max_iter': 144}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:33,739] Trial 37 finished with value: 0.4128571428571429 and parameters: {'C': 5.133656975286771, 'solver': 'saga', 'max_iter': 149}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:34,688] Trial 38 finished with value: 0.4121428571428572 and parameters: {'C': 86.39069183710204, 'solver': 'saga', 'max_iter': 141}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:35,562] Trial 39 finished with value: 0.4121428571428572 and parameters: {'C': 7.919404712658133, 'solver': 'saga', 'max_iter': 128}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:36,423] Trial 40 finished with value: 0.4114285714285715 and parameters: {'C': 1.8366988731221323, 'solver': 'saga', 'max_iter': 121}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:37,279] Trial 41 finished with value: 0.4114285714285715 and parameters: {'C': 2.1102866533754954, 'solver': 'saga', 'max_iter': 116}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:38,106] Trial 42 finished with value: 0.4121428571428572 and parameters: {'C': 1.6905375272098997, 'solver': 'saga', 'max_iter': 112}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:38,942] Trial 43 finished with value: 0.4121428571428572 and parameters: {'C': 0.46062783361370985, 'solver': 'saga', 'max_iter': 120}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:39,665] Trial 44 finished with value: 0.4128571428571429 and parameters: {'C': 1.9674439395894212, 'solver': 'saga', 'max_iter': 100}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:40,511] Trial 45 finished with value: 0.4121428571428572 and parameters: {'C': 9.347693672036032, 'solver': 'saga', 'max_iter': 118}. Best is trial 33 with value: 0.4114285714285715.\n",
      "[I 2025-11-03 11:50:41,356] Trial 46 finished with value: 0.41142857142857137 and parameters: {'C': 0.0011777231967465248, 'solver': 'saga', 'max_iter': 115}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:42,168] Trial 47 finished with value: 0.41714285714285715 and parameters: {'C': 0.0023163813469753596, 'solver': 'saga', 'max_iter': 112}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:42,417] Trial 48 finished with value: 0.41714285714285715 and parameters: {'C': 0.004092378026644808, 'solver': 'lbfgs', 'max_iter': 111}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:43,529] Trial 49 finished with value: 0.41714285714285715 and parameters: {'C': 0.0014636788653139565, 'solver': 'saga', 'max_iter': 124}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:44,393] Trial 50 finished with value: 0.4178571428571428 and parameters: {'C': 0.008614123385901153, 'solver': 'saga', 'max_iter': 108}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:45,357] Trial 51 finished with value: 0.4114285714285715 and parameters: {'C': 4.137909290132676, 'solver': 'saga', 'max_iter': 122}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:46,406] Trial 52 finished with value: 0.4121428571428571 and parameters: {'C': 0.30524809442860174, 'solver': 'saga', 'max_iter': 123}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:47,472] Trial 53 finished with value: 0.41999999999999993 and parameters: {'C': 0.02846152787468745, 'solver': 'saga', 'max_iter': 122}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:48,459] Trial 54 finished with value: 0.4121428571428572 and parameters: {'C': 14.365802935337259, 'solver': 'saga', 'max_iter': 116}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:49,447] Trial 55 finished with value: 0.4121428571428572 and parameters: {'C': 34.072292972654125, 'solver': 'saga', 'max_iter': 131}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[I 2025-11-03 11:50:50,299] Trial 56 finished with value: 0.4164285714285715 and parameters: {'C': 0.09324039599721748, 'solver': 'saga', 'max_iter': 116}. Best is trial 46 with value: 0.41142857142857137.\n",
      "[W 2025-11-03 11:50:50,552] Trial 57 failed with parameters: {'C': 0.5718875797170231, 'solver': 'saga', 'max_iter': 128} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6791/58247853.py\", line 16, in objective_lr\n",
      "    score = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py\", line 544, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py\", line 279, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py\", line 68, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1350, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 547, in _logistic_regression_path\n",
      "    w0, n_iter_i, warm_start_sag = sag_solver(\n",
      "                                   ^^^^^^^^^^^\n",
      "  File \"/home/franio/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py\", line 324, in sag_solver\n",
      "    num_seen, n_iter_ = sag(\n",
      "                        ^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-03 11:50:50,554] Trial 57 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     18\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m score\n\u001B[32m     22\u001B[39m study = optuna.create_study()\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective_lr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m study.best_params\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/study.py:490\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    388\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    389\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    390\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    397\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    398\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    399\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    400\u001B[39m \n\u001B[32m    401\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    488\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    489\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m490\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial_id = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:258\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    251\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    253\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    254\u001B[39m     updated_state == TrialState.FAIL\n\u001B[32m    255\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    256\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    257\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m258\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    259\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m trial._trial_id\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:201\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    200\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    202\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    203\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    204\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 16\u001B[39m, in \u001B[36mobjective_lr\u001B[39m\u001B[34m(trial)\u001B[39m\n\u001B[32m     14\u001B[39m clf = MultiOutputClassifier(LogisticRegression(C=C, solver=solver, max_iter=max_iter, random_state=\u001B[32m42\u001B[39m))\n\u001B[32m     15\u001B[39m cv = KFold(n_splits=\u001B[32m5\u001B[39m, shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m score = \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43maccuracy\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m.mean()\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m score\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    209\u001B[39m         skip_parameter_validation=(\n\u001B[32m    210\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    211\u001B[39m         )\n\u001B[32m    212\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    215\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    217\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    219\u001B[39m     msg = re.sub(\n\u001B[32m    220\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    221\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    222\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    223\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001B[39m, in \u001B[36mcross_val_score\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001B[39m\n\u001B[32m    709\u001B[39m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[32m    710\u001B[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001B[32m--> \u001B[39m\u001B[32m712\u001B[39m cv_results = \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    713\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    714\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    715\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    716\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    717\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mscore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    718\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    719\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    720\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    721\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    722\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    723\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    724\u001B[39m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    726\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[33m\"\u001B[39m\u001B[33mtest_score\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    209\u001B[39m         skip_parameter_validation=(\n\u001B[32m    210\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    211\u001B[39m         )\n\u001B[32m    212\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    215\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    217\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    219\u001B[39m     msg = re.sub(\n\u001B[32m    220\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    221\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    222\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    223\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:423\u001B[39m, in \u001B[36mcross_validate\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[39m\n\u001B[32m    420\u001B[39m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[32m    421\u001B[39m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[32m    422\u001B[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m results = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    424\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    427\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    430\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    431\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    433\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    434\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscore_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    435\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    436\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    437\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    438\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    439\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    440\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\n\u001B[32m    441\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    443\u001B[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[32m    445\u001B[39m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[32m    446\u001B[39m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[32m    447\u001B[39m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     62\u001B[39m config = get_config()\n\u001B[32m     63\u001B[39m iterable_with_config = (\n\u001B[32m     64\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     66\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m     config = {}\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001B[39m, in \u001B[36m_fit_and_score\u001B[39m\u001B[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[39m\n\u001B[32m    886\u001B[39m         estimator.fit(X_train, **fit_params)\n\u001B[32m    887\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m888\u001B[39m         \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    890\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    891\u001B[39m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[32m    892\u001B[39m     fit_time = time.time() - start_time\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py:544\u001B[39m, in \u001B[36mMultiOutputClassifier.fit\u001B[39m\u001B[34m(self, X, Y, sample_weight, **fit_params)\u001B[39m\n\u001B[32m    518\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, Y, sample_weight=\u001B[38;5;28;01mNone\u001B[39;00m, **fit_params):\n\u001B[32m    519\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Fit the model to data matrix X and targets Y.\u001B[39;00m\n\u001B[32m    520\u001B[39m \n\u001B[32m    521\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    542\u001B[39m \u001B[33;03m        Returns a fitted instance.\u001B[39;00m\n\u001B[32m    543\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m544\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    545\u001B[39m     \u001B[38;5;28mself\u001B[39m.classes_ = [estimator.classes_ \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.estimators_]\n\u001B[32m    546\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1466\u001B[39m     estimator._validate_params()\n\u001B[32m   1468\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1469\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1470\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1471\u001B[39m     )\n\u001B[32m   1472\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1473\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py:279\u001B[39m, in \u001B[36m_MultiOutputEstimator.fit\u001B[39m\u001B[34m(self, X, y, sample_weight, **fit_params)\u001B[39m\n\u001B[32m    276\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    277\u001B[39m         routed_params.estimator.fit[\u001B[33m\"\u001B[39m\u001B[33msample_weight\u001B[39m\u001B[33m\"\u001B[39m] = sample_weight\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m \u001B[38;5;28mself\u001B[39m.estimators_ = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.estimators_[\u001B[32m0\u001B[39m], \u001B[33m\"\u001B[39m\u001B[33mn_features_in_\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    287\u001B[39m     \u001B[38;5;28mself\u001B[39m.n_features_in_ = \u001B[38;5;28mself\u001B[39m.estimators_[\u001B[32m0\u001B[39m].n_features_in_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     62\u001B[39m config = get_config()\n\u001B[32m     63\u001B[39m iterable_with_config = (\n\u001B[32m     64\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     66\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m     config = {}\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/multioutput.py:68\u001B[39m, in \u001B[36m_fit_estimator\u001B[39m\u001B[34m(estimator, X, y, sample_weight, **fit_params)\u001B[39m\n\u001B[32m     66\u001B[39m     estimator.fit(X, y, sample_weight=sample_weight, **fit_params)\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m     \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m estimator\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1466\u001B[39m     estimator._validate_params()\n\u001B[32m   1468\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1469\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1470\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1471\u001B[39m     )\n\u001B[32m   1472\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1473\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1350\u001B[39m, in \u001B[36mLogisticRegression.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m   1347\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1348\u001B[39m     n_threads = \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1350\u001B[39m fold_coefs_ = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1352\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1353\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1354\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1355\u001B[39m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1356\u001B[39m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1357\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1358\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1359\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1360\u001B[39m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[43m=\u001B[49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1361\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1362\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1363\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1364\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1365\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1366\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1367\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1368\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1369\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1370\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1371\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1372\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1373\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1375\u001B[39m fold_coefs_, _, n_iter_ = \u001B[38;5;28mzip\u001B[39m(*fold_coefs_)\n\u001B[32m   1376\u001B[39m \u001B[38;5;28mself\u001B[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     62\u001B[39m config = get_config()\n\u001B[32m     63\u001B[39m iterable_with_config = (\n\u001B[32m     64\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     66\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m     config = {}\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:547\u001B[39m, in \u001B[36m_logistic_regression_path\u001B[39m\u001B[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[39m\n\u001B[32m    544\u001B[39m         alpha = (\u001B[32m1.0\u001B[39m / C) * (\u001B[32m1\u001B[39m - l1_ratio)\n\u001B[32m    545\u001B[39m         beta = (\u001B[32m1.0\u001B[39m / C) * l1_ratio\n\u001B[32m--> \u001B[39m\u001B[32m547\u001B[39m     w0, n_iter_i, warm_start_sag = \u001B[43msag_solver\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    548\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    549\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    550\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    551\u001B[39m \u001B[43m        \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    552\u001B[39m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    553\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    554\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    555\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    556\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    557\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    558\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    559\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    560\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwarm_start_sag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    561\u001B[39m \u001B[43m        \u001B[49m\u001B[43mis_saga\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msaga\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    562\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    564\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    565\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    566\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33msolver must be one of \u001B[39m\u001B[33m{\u001B[39m\u001B[33m'\u001B[39m\u001B[33mliblinear\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m\u001B[33mlbfgs\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    567\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[33mnewton-cg\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m\u001B[33msag\u001B[39m\u001B[33m'\u001B[39m\u001B[33m}, got \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m instead\u001B[39m\u001B[33m\"\u001B[39m % solver\n\u001B[32m    568\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Uczenie_maszynowe/ISLP_labs/venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:324\u001B[39m, in \u001B[36msag_solver\u001B[39m\u001B[34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001B[39m\n\u001B[32m    318\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mZeroDivisionError\u001B[39;00m(\n\u001B[32m    319\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCurrent sag implementation does not handle \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    320\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mthe case step_size * alpha_scaled == 1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    321\u001B[39m     )\n\u001B[32m    323\u001B[39m sag = sag64 \u001B[38;5;28;01mif\u001B[39;00m X.dtype == np.float64 \u001B[38;5;28;01melse\u001B[39;00m sag32\n\u001B[32m--> \u001B[39m\u001B[32m324\u001B[39m num_seen, n_iter_ = \u001B[43msag\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcoef_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m    \u001B[49m\u001B[43mintercept_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[43m    \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    334\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m    \u001B[49m\u001B[43malpha_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m    \u001B[49m\u001B[43msum_gradient_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgradient_memory_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m    \u001B[49m\u001B[43mseen_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_seen_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m    \u001B[49m\u001B[43mintercept_sum_gradient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[43m    \u001B[49m\u001B[43mintercept_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    344\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_saga\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    346\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_iter_ == max_iter:\n\u001B[32m    349\u001B[39m     warnings.warn(\n\u001B[32m    350\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe max_iter was reached which means the coef_ did not converge\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    351\u001B[39m         ConvergenceWarning,\n\u001B[32m    352\u001B[39m     )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
